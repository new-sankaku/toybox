# LLM Configuration

# Default settings
default:
  provider: anthropic
  model: claude-3-5-sonnet-20241022
  temperature: 0.7
  max_tokens: 4096

# Provider configurations
providers:
  anthropic:
    models:
      - claude-3-5-sonnet-20241022
      - claude-3-opus-20240229
      - claude-3-haiku-20240307

  openai:
    models:
      - gpt-4-turbo
      - gpt-4o
      - gpt-3.5-turbo

  deepseek:
    base_url: https://api.deepseek.com/v1
    models:
      - deepseek-chat
      - deepseek-coder

  custom:
    base_url: ${CUSTOM_LLM_URL}
    models:
      - custom-model

# Agent-specific LLM overrides (optional)
agent_overrides:
  coder:
    provider: anthropic
    model: claude-3-5-sonnet-20241022
  planner:
    provider: anthropic
    model: claude-3-5-sonnet-20241022
  debugger:
    provider: anthropic
    model: claude-3-5-sonnet-20241022
