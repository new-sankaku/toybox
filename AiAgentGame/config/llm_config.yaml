# LLM Configuration

# Application settings
app:
  language: ja  # ja=日本語, en=English
  output_dir: ./output  # 作業ファイルの出力先

# Default settings
default:
  provider: anthropic
  model: claude-sonnet-4-20250514
  temperature: 0.7
  max_tokens: 4096

# Provider configurations
providers:
  anthropic:
    models:
      - claude-sonnet-4-20250514
      - claude-3-opus-20240229
      - claude-3-haiku-20240307

  openai:
    models:
      - gpt-4-turbo
      - gpt-4o
      - gpt-3.5-turbo

  deepseek:
    base_url: https://api.deepseek.com/v1
    models:
      - deepseek-chat
      - deepseek-coder

  custom:
    base_url: ${CUSTOM_LLM_URL}
    models:
      - custom-model

# Agent-specific LLM overrides (optional)
agent_overrides:
  coder:
    provider: anthropic
    model: claude-sonnet-4-20250514
  planner:
    provider: anthropic
    model: claude-sonnet-4-20250514
  debugger:
    provider: anthropic
    model: claude-sonnet-4-20250514
